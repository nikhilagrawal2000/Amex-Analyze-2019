{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data reading complete\n",
      "       application_key mvar1    mvar2   mvar3    mvar4  mvar5    mvar6  \\\n",
      "0               350053  1753   0.5001   0.000   0.0000  0.000      206   \n",
      "1               350054  1894   1.9701   0.000   0.0000  0.000      297   \n",
      "2               350055  1774   0.1718   0.000   0.0000  0.000      197   \n",
      "3               350056  1586   0.1123   5.299   0.0000  0.000  missing   \n",
      "4               350057  1832   1.4442   0.000   0.0000  0.000      179   \n",
      "5               350058  1838   0.0544   0.241   0.0000  0.000      882   \n",
      "6               350059  1743   1.0753   0.272   0.0000  0.000      397   \n",
      "7               350060  1935   0.5601   0.000   0.0000  0.000      496   \n",
      "8               350061  1885   0.0811   0.000   0.0000  0.000     7369   \n",
      "9               350062  1730   0.7444   0.000   0.0000  0.000        0   \n",
      "10              350063  1731   0.5097   0.000   0.0000  0.000     2433   \n",
      "11              350064  1755   0.3013   0.000   0.0000  0.000      261   \n",
      "12              350065  1739   2.2909   0.000   0.0000  0.000        0   \n",
      "13              350066  1562   0.0000  34.611   3.7845  0.000  missing   \n",
      "14              350067  1798   5.0825   0.000   0.0000  0.000      259   \n",
      "15              350068  1684   1.5479   1.338   0.0000  0.000  missing   \n",
      "16              350069  1789   0.0000   1.428   0.0000  0.000     2478   \n",
      "17              350070  1862   0.2401   0.000   0.0000  0.000     1487   \n",
      "18              350071  1767   0.3001   1.514   0.0000  0.000      991   \n",
      "19              350072  1802   0.6364   0.000   0.0000  0.000       96   \n",
      "20              350073  1780   1.9559   0.000   0.0000  0.000      191   \n",
      "21              350074  1714   2.2664   0.000   0.0000  0.000       31   \n",
      "22              350075  1923   0.0880   0.000   0.0000  0.000     5946   \n",
      "23              350076  1743   1.7208   2.295   0.0000  0.000      159   \n",
      "24              350077  1700   1.6605   0.000   0.0000  0.000        0   \n",
      "25              350078  1922      NaN   0.000   0.0000  0.000     4524   \n",
      "26              350079  1777   0.4120   0.000   0.0000  0.000      369   \n",
      "27              350080  1811   0.9117   0.410   0.0000  0.410      297   \n",
      "28              350081  1658   2.3829  37.127  10.3678  0.000        0   \n",
      "29              350082  1827   0.2801   0.000   0.0000  0.000      678   \n",
      "...                ...   ...      ...     ...      ...    ...      ...   \n",
      "24970           375023  1734   0.9279   0.520   0.0000  0.000      256   \n",
      "24971           375024  1849   1.8305   0.000   0.0000  0.000     2251   \n",
      "24972           375025  1739   1.5251   2.727   0.0000  2.727        8   \n",
      "24973           375026  1642   0.0000   3.353   1.2114  0.000  missing   \n",
      "24974           375027  1709   3.6801   7.583   3.1371  0.000      297   \n",
      "24975           375028  1890   0.0000   0.000   0.0000  0.000     1982   \n",
      "24976           375029  1727   1.8448  15.181   0.0000  0.000     2234   \n",
      "24977           375030  1789   1.2994   0.000   0.0000  0.000      364   \n",
      "24978           375031  1706   0.4997   0.000   0.0000  0.000       98   \n",
      "24979           375032  1638   4.6802  16.751   2.6642  0.000  missing   \n",
      "24980           375033  1855   1.9965   0.000   0.0000  0.000      350   \n",
      "24981           375034  1790   0.2050   0.000   0.0000  0.000      237   \n",
      "24982           375035  1546   0.3491  50.803   4.2695  0.000  missing   \n",
      "24983           375036  1777   3.9629   0.968   0.0000  0.000       14   \n",
      "24984           375037  1943      NaN   0.000   0.0000  0.000        0   \n",
      "24985           375038  1691   0.1663   1.979   0.0000  0.000        0   \n",
      "24986           375039  1681   0.1739   9.006   0.0000  6.568        0   \n",
      "24987           375040  1723   1.0570   0.285   0.0000  0.000      248   \n",
      "24988           375041  1693   1.2145   0.000   0.0000  0.000       18   \n",
      "24989           375042  1592   6.4805   5.250   0.0000  1.204  missing   \n",
      "24990           375043  1641   0.6601   8.614   0.0000  0.000  missing   \n",
      "24991           375044  1740   0.3901   4.322   0.0000  0.000      490   \n",
      "24992           375045  1651   2.4909   1.335   0.9108  0.000        4   \n",
      "24993           375046  1729   1.3601   0.218   0.0000  0.000        0   \n",
      "24994           375047  1730   1.6701   5.554   0.0000  0.000      104   \n",
      "24995           375048  1715  12.0002   0.000   0.0000  0.000  missing   \n",
      "24996           375049  1800   0.0551   0.000   0.0000  0.000     5946   \n",
      "24997           375050  1686   1.3301   2.025   0.0000  2.025  missing   \n",
      "24998           375051  1826      NaN   0.428   0.0000  0.000     3568   \n",
      "24999           375052  1916   0.1394   0.000   0.0000  0.000    18889   \n",
      "\n",
      "         mvar7    mvar8    mvar9  ...   mvar38 mvar39   mvar40   mvar41  \\\n",
      "0        19179      206    14221  ...        1      0  missing   20.551   \n",
      "1        19820    19820   176895  ...        3      0  missing   63.047   \n",
      "2         2563      877     8869  ...        1      0  missing   83.797   \n",
      "3      missing  missing  missing  ...        1     na  missing  missing   \n",
      "4         7577      179    21059  ...        3      0   96.052   66.665   \n",
      "5        14039    10976   278941  ...        4      0  missing    77.78   \n",
      "6        16141     3568    69482  ...        6      0  missing   67.159   \n",
      "7        44919    17115   124814  ...        9      0  missing  missing   \n",
      "8        19264    19264    59956  ...        1      0  missing  missing   \n",
      "9         2103      582    16429  ...        9      0  missing  missing   \n",
      "10        8673     8673     6739  ...        2      0  missing  missing   \n",
      "11        4051      261      297  ...        3      0  missing  missing   \n",
      "12        7620     7620    64983  ...       11      0  missing       95   \n",
      "13          18  missing      198  ...        7      1   124.91   99.934   \n",
      "14        3359     2973    22099  ...        5      0  missing   76.881   \n",
      "15     missing  missing  missing  ...        3     na  missing  missing   \n",
      "16       13874    13874    98011  ...        4      0  missing  missing   \n",
      "17       12310     3964     7928  ...        6      0  missing   77.419   \n",
      "18        2478     2478     8790  ...        1      0  missing  missing   \n",
      "19       18759    10905    51037  ...        3      0  missing   58.972   \n",
      "20       12525    12525    18932  ...        7      0  missing      100   \n",
      "21        1671       57      396  ...        6      0  missing   91.666   \n",
      "22       53893    24739   128435  ...        2      0  missing   90.429   \n",
      "23        3621     2323     9018  ...        8      0  missing   82.323   \n",
      "24        1037       46      892  ...        5      0  missing  missing   \n",
      "25       15530    14819   116154  ...        3      0  missing  missing   \n",
      "26        6201     6201    66477  ...       12      0  missing  missing   \n",
      "27       27717     9815   110001  ...        3      0  missing   74.996   \n",
      "28         396        0     6566  ...       14      0  missing  missing   \n",
      "29        1189     1189      892  ...        3      0  missing  missing   \n",
      "...        ...      ...      ...  ...      ...    ...      ...      ...   \n",
      "24970    11643     1524    16748  ...        7      0  missing  missing   \n",
      "24971    33275     7505    44843  ...        2      0  missing   91.701   \n",
      "24972     2129      720     5896  ...        6      0  109.251   94.127   \n",
      "24973     6290  missing  missing  ...        1      0  missing    37.89   \n",
      "24974     8132      297     1041  ...       32      0   81.029  missing   \n",
      "24975    15162    15162    68181  ...        2      0   98.043   55.197   \n",
      "24976     2754     2234     2676  ...        4      0  missing  missing   \n",
      "24977    17838    17838     8424  ...        5      0  109.307   75.052   \n",
      "24978      297       98      546  ...        7      0  missing  missing   \n",
      "24979     7937  missing     3032  ...        3      1  102.709   13.882   \n",
      "24980    30203    22656   168999  ...        2      0  missing  missing   \n",
      "24981    18018    13297     3914  ...        5      0  missing  missing   \n",
      "24982  missing  missing     3330  ...        8      0  missing  missing   \n",
      "24983    23707    23707    33432  ...       12      0  missing   80.934   \n",
      "24984    24775    24775    80772  ...        0      0  missing  missing   \n",
      "24985     9591     2627    46903  ...        5      0   84.801   63.855   \n",
      "24986     3004     2251     6818  ...        1      1   96.309  missing   \n",
      "24987    28479    28479    16352  ...        7      0  missing  missing   \n",
      "24988      100      100      991  ...        3      0  missing  missing   \n",
      "24989        0  missing  missing  ...        3      0      100  missing   \n",
      "24990        0  missing  missing  ...        3      0      100  missing   \n",
      "24991    29460     9449    42047  ...        3      0  missing  missing   \n",
      "24992     3163        4     1982  ...       10      0  missing   82.382   \n",
      "24993     5675      167    15071  ...        5      0  missing  missing   \n",
      "24994     5692      496     4410  ...        5      0  missing   79.485   \n",
      "24995      991  missing     8751  ...        1      0  missing  missing   \n",
      "24996    14867     9613    46490  ...        4      0  missing  missing   \n",
      "24997        0  missing     4582  ...        0      0  124.171  missing   \n",
      "24998    26277     9058    72739  ...        2      0  missing   50.119   \n",
      "24999    18889    18889    28343  ...        0      0  missing  missing   \n",
      "\n",
      "        mvar42 mvar43   mvar44 mvar45 mvar46 mvar47  \n",
      "0      0.42105      3  0.85661     na      0      L  \n",
      "1            0     15  0.94391      0      0      C  \n",
      "2      0.33333      3  0.76467      0      0      C  \n",
      "3          1.5      0      NaN     na     na      C  \n",
      "4            0     23  0.79190      0      0      L  \n",
      "5            0     21  0.92462      0      0      L  \n",
      "6            0     14  0.71347      0      0      L  \n",
      "7            0     15  0.92403      0      0      L  \n",
      "8            0      5  0.89760      0     na      L  \n",
      "9      0.05882     14  0.40529     na      0      C  \n",
      "10     0.23529      1  0.64242      0     na      C  \n",
      "11     0.33333      2  0.99142     na      0      C  \n",
      "12     0.05882     16  0.44167     na      0      C  \n",
      "13       0.875      1  0.84592      1      1      C  \n",
      "14     0.05882     13  0.43365      0      0      C  \n",
      "15         1.5      0      NaN     na     na      C  \n",
      "16        0.05     13  0.51231     na     na      L  \n",
      "17           0      7  0.56685      0      0      C  \n",
      "18         0.1      3      NaN     na     na      C  \n",
      "19           0      9  0.59409      0      0      C  \n",
      "20           0      7  0.92752      0      0      C  \n",
      "21       0.375      5  0.34836     na      0      C  \n",
      "22           0      9  0.88554      0      0      C  \n",
      "23         0.1      9  0.59442     na      0      C  \n",
      "24         0.2      5  0.94826     na      0      L  \n",
      "25           0     12  0.91550      0      0      L  \n",
      "26     0.03846     23  0.15159     na     na      C  \n",
      "27           0     15  0.56671      0      0      C  \n",
      "28     0.57692      8  0.35339     na      2      C  \n",
      "29           0      2  1.00000     na     na      C  \n",
      "...        ...    ...      ...    ...    ...    ...  \n",
      "24970        0     10  0.38078     na      0      L  \n",
      "24971        0      4  0.92111      0      0      L  \n",
      "24972  0.36842     12  0.52903     na      0      C  \n",
      "24973  0.83333      0  1.00000     na      0      C  \n",
      "24974  0.59459     11  0.42680     na      2      C  \n",
      "24975        0     15  0.27143     na      0      C  \n",
      "24976  0.66667      5  0.87890      0      0      C  \n",
      "24977  0.15385      8  0.69694      0      0      L  \n",
      "24978  0.66667      4  1.00000     na      0      C  \n",
      "24979      0.5      4  0.72640     na      0      C  \n",
      "24980        0     12  0.74106      0     na      L  \n",
      "24981      0.2      2  0.41582     na      0      C  \n",
      "24982   0.7037      2  1.00000      1      1      C  \n",
      "24983     0.04     15  0.64752     na      0      L  \n",
      "24984        0      6  0.97068      0     na      C  \n",
      "24985  0.03448     14  0.43441     na      0      C  \n",
      "24986  0.71429      2  0.88908      0      0      C  \n",
      "24987        0      6  0.72344     na      0      C  \n",
      "24988        0      3  0.36619     na     na      C  \n",
      "24989        1      1  0.50649     na     na      C  \n",
      "24990        1      1  1.00000     na     na      L  \n",
      "24991      0.2      4  0.88957      1      0      L  \n",
      "24992  0.61538      3  0.93745     na      0      L  \n",
      "24993   0.2381     13  0.71866     na      0      C  \n",
      "24994  0.30769      4  0.93312     na      0      C  \n",
      "24995  0.07692      4      NaN     na      0      C  \n",
      "24996  0.05882      8  0.99859      0      0      L  \n",
      "24997      0.3      2  0.77519     na     na      L  \n",
      "24998  0.03333     11  0.40343     na      0      C  \n",
      "24999        0      5  0.99663      0      0      C  \n",
      "\n",
      "[25000 rows x 48 columns]\n",
      "data application_key dropped\n",
      "data mvar47 dropped\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#Reading data\n",
    "\n",
    "df_training = pd.read_csv(\"training_dataset.csv\")\n",
    "df_eval = pd.read_csv(\"Evaluation_dataset.csv\")\n",
    "df_leader = pd.read_csv(\"leaderboard_dataset.csv\")\n",
    "#df_datadict = pd.read_csv(\"Data_Dictionary.csv\")\n",
    "\n",
    "print(\"data reading complete\")\n",
    "\n",
    "print(df_leader)\n",
    "\n",
    "df_training = df_training.drop(['application_key'],axis=1)\n",
    "application_key = df_leader.loc[:, 'application_key']\n",
    "\n",
    "df_leader = df_leader.drop(['application_key'],axis=1)\n",
    "\n",
    "print(\"data application_key dropped\")\n",
    "\n",
    "mvar47 = df_training.loc[:, 'mvar47']\n",
    "mvar47leader = df_leader.loc[:, 'mvar47']\n",
    "\n",
    "df_training = df_training.drop(['mvar47'],axis=1)\n",
    "df_leader = df_leader.drop(['mvar47'],axis=1)\n",
    "\n",
    "print(\"data mvar47 dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed\n",
      "      mvar1   mvar2   mvar3  mvar4  mvar5  mvar6   mvar7   mvar8   mvar9  \\\n",
      "0      1696  1.6541   0.000  0.000  0.000      0    6015     322   40369   \n",
      "1      1846  0.8095   0.000  0.000  0.000    102    7532    3171   18234   \n",
      "2      1745  0.4001   0.000  0.000  0.000      0    2536       0       0   \n",
      "3      1739  0.2193   0.000  0.000  0.000   1982   26440    4955   20316   \n",
      "4      1787  0.0118   0.225  0.000  0.000   5451    5494    5494    7987   \n",
      "5      1579  0.0000   3.502  0.000  0.000      0       0       0       0   \n",
      "6      1818  0.4001   0.000  0.000  0.000      0    1088       0    1536   \n",
      "7         0  0.0000   0.000  0.000  0.000      0       0       0       0   \n",
      "8      1836  0.1358   0.000  0.000  0.000    347   38964   17828   70729   \n",
      "9      1839  0.1981   0.000  0.000  0.000    793    6131    6045   48959   \n",
      "10     1903  0.0000   0.000  0.000  0.000     22   19518    9910   90618   \n",
      "11     1681  1.5888   5.685  3.566  0.000     93    3554     439    2527   \n",
      "12     1841  0.5388   0.000  0.000  0.000   1487   19449   19449    6739   \n",
      "13     1794  1.9684   0.000  0.000  0.000    856    8609    8609   60545   \n",
      "14     1669  3.8558  18.465  6.292  1.200      0     142       0      38   \n",
      "15     1583  3.0284  16.325  0.000  0.000      0       0       0   51450   \n",
      "16     1899  0.0970   0.000  0.000  0.000   1015   13379   13379  246906   \n",
      "17     1690  8.7747  10.437  0.000  0.000    122     623     299    1140   \n",
      "18     1599  0.8601   1.525  1.525  0.000      0     878       0       0   \n",
      "19     1859  0.0155   0.368  0.000  0.000    424   86509   12451   86635   \n",
      "20     1880  2.6101   0.000  0.000  0.000      0   19252    6342   59601   \n",
      "21     1852  3.6201   0.000  0.000  0.000    799   16515   16515  110651   \n",
      "22     1655  3.0268  14.748  0.000  0.000     48      48      48     198   \n",
      "23     1863  0.0401   0.000  0.000  0.000   1487    4955    4955   22902   \n",
      "24     1753  0.2251   0.000  0.000  0.000   1124    1124    1124       0   \n",
      "25     1894  0.0318   0.000  0.000  0.000   4655    7433    7433   25667   \n",
      "26     1803  0.3993   0.000  0.000  0.000    496   10505     496     991   \n",
      "27     1932  0.3276   0.000  0.000  0.000   6982   21569   18829  187209   \n",
      "28     1714  5.1904   0.770  0.000  0.000      0    1889     595   12574   \n",
      "29        0  2.0457   4.514  0.000  0.000      0       0       0       0   \n",
      "...     ...     ...     ...    ...    ...    ...     ...     ...     ...   \n",
      "79970  1834  1.2164   0.000  0.000  0.000   2212    5244    4203   16743   \n",
      "79971  1729  1.3696   0.000  0.000  0.000    356    4218    1982   18657   \n",
      "79972  1753  5.8283   0.000  0.000  0.000    180    4014     617    3667   \n",
      "79973  1748  1.9635   0.642  0.000  0.000    291    3469    3469   13131   \n",
      "79974  1771  1.7588   0.000  0.000  0.000     66   12626    6433   27946   \n",
      "79975  1766  0.9540   0.000  0.000  0.000   1140   10207   10207   55001   \n",
      "79976  1822  0.0000   1.853  1.853  0.000   2581   13361    5946   31018   \n",
      "79977  1824  0.5634   0.000  0.000  0.000   3964    4683    4683       0   \n",
      "79978  1914  0.0544   0.000  0.000  0.000   3469   20424   20424   78774   \n",
      "79979  1600  2.6649  18.282  1.078  2.678      0    7205       0     956   \n",
      "79980  1822  0.5851   0.000  0.000  0.000      0   23685   23685  208174   \n",
      "79981  1693  0.1828  17.767  2.024  0.000    114   27514     384    2329   \n",
      "79982  1735  3.1701   0.260  0.000  0.000    117     892     117    3766   \n",
      "79983  1671  0.1380   0.000  0.000  0.000      0     491       0       0   \n",
      "79984  1924  0.1221   0.000  0.000  0.000   2478  266683  266683  405300   \n",
      "79985  1670  0.0347   9.836  0.000  0.000    212    7848     491   29785   \n",
      "79986  1901  0.1782   0.000  0.000  0.000   4955   21753   12673   70293   \n",
      "79987  1835  0.5372   0.000  0.000  0.000      0   29723    3964   66770   \n",
      "79988  1927  0.0410   0.000  0.000  0.000  22000   30046   24165   75019   \n",
      "79989     0  0.1451   0.000  0.000  0.000      0       0       0       0   \n",
      "79990  1941  0.4834   0.000  0.000  0.000  10846   52806   35478  136461   \n",
      "79991  1899  0.0000   0.000  0.000  0.000   7310   14519   14519    5252   \n",
      "79992  1761  2.0999   0.000  0.000  0.000     47   13477    1814    9320   \n",
      "79993  1700  0.3831   0.000  0.000  0.000    344     344     344     991   \n",
      "79994  1910  0.0000   0.000  0.000  0.000   4955   47306   47306   88124   \n",
      "79995  1736  2.1740   0.000  0.000  0.000     11    4248    1577   13379   \n",
      "79996  1724  0.0000   1.108  0.768  0.000      0   64041       0   10926   \n",
      "79997  1605  0.2901  11.561  0.937  2.976      0    2277       0    3964   \n",
      "79998  1780  1.1874   0.000  0.000  0.000      0    6356    4802    3206   \n",
      "79999  1727  1.9288   1.441  0.000  0.000      0   25773    2869  132985   \n",
      "\n",
      "       mvar10     ...     mvar38 mvar39   mvar40  mvar41   mvar42 mvar43  \\\n",
      "0       18414     ...          4      1    73.78  82.547  0.08696     10   \n",
      "1       13664     ...          2      0   99.129       0        0     13   \n",
      "2        2536     ...          1      0        0   29.29        0      1   \n",
      "3       37013     ...          2      0   96.272       0  0.15385      3   \n",
      "4        4696     ...          2      0  115.019       0        0      1   \n",
      "5           0     ...          2      0        0       0      1.5      0   \n",
      "6        1498     ...          0      0   88.171       0        0      2   \n",
      "7           0     ...          0      0        0       0        0      0   \n",
      "8       65843     ...          2      0        0       0        0     10   \n",
      "9       31640     ...          0      0        0   45.59  0.08824     14   \n",
      "10     110271     ...          2      0        0       0        0     17   \n",
      "11       7086     ...          5      1        0       0  0.61111      7   \n",
      "12       6612     ...          6      0        0       0        0      5   \n",
      "13      24893     ...          1      0        0       0        0     13   \n",
      "14        142     ...         15      0  107.825  98.664     0.56     11   \n",
      "15          0     ...          4      0        0       0  0.32353      2   \n",
      "16      56533     ...          2      0   10.384       0        0     19   \n",
      "17       2043     ...         12      0        0       0  0.63636      5   \n",
      "18        878     ...          1      1        0  91.175      0.8      0   \n",
      "19     142081     ...          2      0        0       0        0     12   \n",
      "20      86906     ...         14      0        0  72.497        0     14   \n",
      "21      41311     ...          2      0        0       0        0     13   \n",
      "22         48     ...          4      0        0       0        1      1   \n",
      "23      21772     ...          4      0   96.895       0        0     12   \n",
      "24       1124     ...          1      0        0       0        0      0   \n",
      "25      12345     ...          1      0        0       0        0      3   \n",
      "26      18163     ...          1      0   91.752  87.306      0.2      5   \n",
      "27     113813     ...          2      0        0       0        0     11   \n",
      "28       4825     ...          8      0        0       0  0.35714      6   \n",
      "29          0     ...          4      0        0       0  1.16667      0   \n",
      "...       ...     ...        ...    ...      ...     ...      ...    ...   \n",
      "79970   13831     ...          8      0        0  97.398        0      8   \n",
      "79971    8921     ...          7      0        0  83.663  0.09091      6   \n",
      "79972    9786     ...         10      0        0  87.094  0.11111      9   \n",
      "79973   14393     ...         12      0        0  92.244     0.44     14   \n",
      "79974   24401     ...          4      0        0  40.477        0     10   \n",
      "79975   20636     ...         13      0        0       0     0.05     14   \n",
      "79976   76774     ...          4      0   73.611  44.656  0.03448     20   \n",
      "79977    8647     ...          2      0        0       0        0      0   \n",
      "79978   27856     ...          1      0        0       0        0      8   \n",
      "79979    7360     ...          9      1  132.335  56.867  0.55263     14   \n",
      "79980   55719     ...          3      0        0       0        0     17   \n",
      "79981   48080     ...          4      0   74.814       0  0.17857      5   \n",
      "79982    1265     ...          3      0        0  99.026        0      2   \n",
      "79983     491     ...          1      0        0       0      0.8      2   \n",
      "79984  390558     ...          4      0        0  70.799        0     13   \n",
      "79985   16226     ...          5      0        0    78.7  0.13636     10   \n",
      "79986   62980     ...          5      0        0  61.301        0     10   \n",
      "79987   85900     ...          3      0        0       0        0      9   \n",
      "79988   88343     ...          3      0        0  19.444        0      7   \n",
      "79989       0     ...          1      0        0       0      1.5      0   \n",
      "79990  176240     ...          1      0        0       0  0.05882      8   \n",
      "79991    4949     ...          1      0        0       0        0      3   \n",
      "79992    2500     ...          5      0        0       0    0.125      5   \n",
      "79993     344     ...          3      0        0       0  0.66667      2   \n",
      "79994  107148     ...          2      0        0       0        0      4   \n",
      "79995    6671     ...          4      0        0  78.378        0      4   \n",
      "79996   84839     ...          5      0        0  38.325  0.16667     14   \n",
      "79997    5709     ...          5      2   101.85  93.142      0.5      4   \n",
      "79998   18180     ...          8      0        0  77.022  0.06061      9   \n",
      "79999   71788     ...          4      0     32.4       0  0.07143     12   \n",
      "\n",
      "        mvar44 mvar45 mvar46 default_ind  \n",
      "0      0.63899      0      0           0  \n",
      "1      0.63836      0      0           1  \n",
      "2      1.00000      0      0           1  \n",
      "3      0.53241      0      0           0  \n",
      "4      0.92665      0      0           0  \n",
      "5      0.00000      0      0           1  \n",
      "6      0.87224      0      0           1  \n",
      "7      0.00000      0      0           0  \n",
      "8      0.89868      0      0           0  \n",
      "9      0.33834      0      0           0  \n",
      "10     0.80620      0      0           0  \n",
      "11     0.81172      0      0           0  \n",
      "12     0.98031      0      0           0  \n",
      "13     0.35724      0      0           0  \n",
      "14     0.29169      0      1           0  \n",
      "15     0.00000      0      0           0  \n",
      "16     0.47480      0      0           0  \n",
      "17     0.94951      0      0           0  \n",
      "18     1.00000      0      0           1  \n",
      "19     0.34730      0      0           0  \n",
      "20     0.28708      0      0           0  \n",
      "21     0.75349      0      0           0  \n",
      "22     1.00000      0      0           1  \n",
      "23     0.40853      0      0           0  \n",
      "24     1.00000      0      0           1  \n",
      "25     0.99419      0      0           0  \n",
      "26     0.75289      0      0           0  \n",
      "27     0.99710      0      0           0  \n",
      "28     0.85082      0      0           0  \n",
      "29     0.00000      0      0           0  \n",
      "...        ...    ...    ...         ...  \n",
      "79970  0.58040      0      0           0  \n",
      "79971  0.62632      0      0           0  \n",
      "79972  0.59364      0      0           0  \n",
      "79973  0.83809      0      0           0  \n",
      "79974  0.46863      0      0           0  \n",
      "79975  0.54754      0      0           0  \n",
      "79976  0.23177      0      0           0  \n",
      "79977  0.67222      0      0           0  \n",
      "79978  1.00000      0      0           0  \n",
      "79979  0.11763      0      0           1  \n",
      "79980  0.81438      0      0           0  \n",
      "79981  0.53340      0      0           0  \n",
      "79982  0.96747      0      0           1  \n",
      "79983  1.00000      0      0           0  \n",
      "79984  0.75322      0      0           0  \n",
      "79985  0.85771      0      0           0  \n",
      "79986  0.86356      0      0           0  \n",
      "79987  0.41685      0      0           0  \n",
      "79988  0.53750      0      0           0  \n",
      "79989  0.00000      0      0           0  \n",
      "79990  0.84170      0      0           0  \n",
      "79991  0.44615      0      0           0  \n",
      "79992  0.73640      0      0           1  \n",
      "79993  0.97374      0      0           1  \n",
      "79994  0.79867      0      0           0  \n",
      "79995  0.43829      0      0           0  \n",
      "79996  0.57931      0      0           0  \n",
      "79997  0.42069      0      0           1  \n",
      "79998  0.53251      0      0           0  \n",
      "79999  0.68482      0      0           1  \n",
      "\n",
      "[80000 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "#replace all missing values with mean of existing values in training set\n",
    "#same can be done for testing set but data leakage can occur\n",
    "\n",
    "df_training = df_training.replace('missing', np.nan)\n",
    "df_training = df_training.replace('na', np.nan)\n",
    "df_training = df_training.replace('N/A', np.nan)\n",
    "\n",
    "df_training = df_training.fillna(0)\n",
    "\n",
    "df_leader = df_leader.replace('missing', np.nan)\n",
    "df_leader = df_leader.replace('na', np.nan)\n",
    "df_leader = df_leader.replace('N/A', np.nan)\n",
    "\n",
    "df_leader = df_leader.fillna(0)\n",
    "\n",
    "print(\"data processed\")\n",
    "\n",
    "#df_training = (df_training - df_training.mean()) / (df_training.max() - df_training.min())\n",
    "#for head in df_training:\n",
    "    #df_training[head] = np.sqrt(df_training[head])\n",
    "\n",
    "#print(\"data normalised\")\n",
    "print(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people: 80000\n",
      "Number of features: 46\n"
     ]
    }
   ],
   "source": [
    "#general informations\n",
    "\n",
    "n_people = df_training.shape[0]\n",
    "n_features = df_training.shape[1]-1\n",
    "print(\"Total number of people: {}\".format(n_people))\n",
    "print(\"Number of features: {}\".format(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['mvar1', 'mvar2', 'mvar3', 'mvar4', 'mvar5', 'mvar6', 'mvar7', 'mvar8', 'mvar9', 'mvar10', 'mvar11', 'mvar12', 'mvar13', 'mvar14', 'mvar15', 'mvar16', 'mvar17', 'mvar18', 'mvar19', 'mvar20', 'mvar21', 'mvar22', 'mvar23', 'mvar24', 'mvar25', 'mvar26', 'mvar27', 'mvar28', 'mvar29', 'mvar30', 'mvar31', 'mvar32', 'mvar33', 'mvar34', 'mvar35', 'mvar36', 'mvar37', 'mvar38', 'mvar39', 'mvar40', 'mvar41', 'mvar42', 'mvar43', 'mvar44', 'mvar45', 'mvar46']\n",
      "Target column: default_ind\n",
      "\n",
      "Feature values:-\n",
      "  mvar1   mvar2  mvar3  mvar4  mvar5 mvar6  mvar7 mvar8  mvar9 mvar10  ...    \\\n",
      "0  1696  1.6541  0.000    0.0    0.0     0   6015   322  40369  18414  ...     \n",
      "1  1846  0.8095  0.000    0.0    0.0   102   7532  3171  18234  13664  ...     \n",
      "2  1745  0.4001  0.000    0.0    0.0     0   2536     0      0   2536  ...     \n",
      "3  1739  0.2193  0.000    0.0    0.0  1982  26440  4955  20316  37013  ...     \n",
      "4  1787  0.0118  0.225    0.0    0.0  5451   5494  5494   7987   4696  ...     \n",
      "\n",
      "  mvar37 mvar38 mvar39   mvar40  mvar41   mvar42 mvar43   mvar44 mvar45 mvar46  \n",
      "0     10      4      1    73.78  82.547  0.08696     10  0.63899      0      0  \n",
      "1      0      2      0   99.129       0        0     13  0.63836      0      0  \n",
      "2      0      1      0        0   29.29        0      1  1.00000      0      0  \n",
      "3      3      2      0   96.272       0  0.15385      3  0.53241      0      0  \n",
      "4      3      2      0  115.019       0        0      1  0.92665      0      0  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data normalised\n"
     ]
    }
   ],
   "source": [
    "#preparing data\n",
    "\n",
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(df_training.columns[:-1])  # all columns but last are features\n",
    "target_col = df_training.columns[-1] # last column is the target/label\n",
    "print(\"Feature column(s):-\\n{}\".format(feature_cols))\n",
    "print( \"Target column: {}\".format(target_col))\n",
    "\n",
    "feature_cols_leader = list(df_leader.columns[:])  # all columns but last are features\n",
    "\n",
    "X_all = df_training[feature_cols]  # feature values for all people\n",
    "y_all = df_training[target_col]  # corresponding targets/labels\n",
    "\n",
    "X_leader = df_leader[feature_cols_leader]\n",
    "\n",
    "print (\"\\nFeature values:-\")\n",
    "print(X_all.head())  # print the first 5 rows\n",
    "\n",
    "X_all = X_all.convert_objects(convert_numeric=True)\n",
    "X_leader = X_leader.convert_objects(convert_numeric=True)\n",
    "\n",
    "\n",
    "for head in X_all:\n",
    "    series = X_all[head]\n",
    "    mean = series.mean()\n",
    "    maximum = series.max()\n",
    "    minimum = series.min()\n",
    "    series = (series - minimum)/(maximum - minimum)\n",
    "    X_all[head] = series\n",
    "    \n",
    "for head in X_leader:\n",
    "    series = X_leader[head]\n",
    "    mean = series.mean()\n",
    "    maximum = series.max()\n",
    "    minimum = series.min()\n",
    "    series = (series - minimum)/(maximum - minimum)\n",
    "    X_leader[head] = series\n",
    "    \n",
    "\n",
    "print(\"data normalised\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (47):-\n",
      "['mvar1', 'mvar2', 'mvar3', 'mvar4', 'mvar5', 'mvar6', 'mvar7', 'mvar8', 'mvar9', 'mvar10', 'mvar11', 'mvar12', 'mvar13', 'mvar14', 'mvar15', 'mvar16', 'mvar17', 'mvar18', 'mvar19', 'mvar20', 'mvar21', 'mvar22', 'mvar23', 'mvar24', 'mvar25', 'mvar26', 'mvar27', 'mvar28', 'mvar29', 'mvar30', 'mvar31', 'mvar32', 'mvar33', 'mvar34', 'mvar35', 'mvar36', 'mvar37', 'mvar38', 'mvar39', 'mvar40', 'mvar41', 'mvar42', 'mvar43', 'mvar44', 'mvar45', 'mvar46', 'mvar47']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['C', 'L'], [1, 0])\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        #if col_data.dtype == object:\n",
    "            #col_data = pd.get_dummies(col_data, prefix=col)\n",
    "\n",
    "        outX = outX.join(col_data)  # collect columns in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "X_leader = preprocess_features(X_leader)\n",
    "mvar47 = mvar47.replace('C',0)\n",
    "mvar47 = mvar47.replace('L',1)\n",
    "mvar47leader = mvar47leader.replace('C',0)\n",
    "mvar47leader = mvar47leader.replace('L',1)\n",
    "\n",
    "X_all = pd.concat((X_all,mvar47),axis =1)\n",
    "X_leader = pd.concat((X_leader,mvar47leader),axis =1)\n",
    "\n",
    "print(\"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 72000 samples\n",
      "Test set: 8000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# preparing number of training and test samples\n",
    "num_all = df_training.shape[0]  # same as len(df_training)\n",
    "num_train = 72000 # about 90% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn import cross_validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_all, y_all, test_size=num_test)\n",
    "print(\"Training set: {} samples\".format(X_train.shape[0]))\n",
    "print (\"Test set: {} samples\".format(X_test.shape[0]))\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 3.339\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Training {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): {:.3f}\".format(end - start))\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "#clf = SVC(gamma='auto')\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.269\n",
      "F1 score for training set: 0.967322159932611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Predicting labels using {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print( \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label=1)\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print (\"F1 score for training set: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.031\n",
      "F1 score for test set: 0.45594855305466236\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n",
    "\n",
    "predict_leader = clf.predict(X_leader)\n",
    "\n",
    "data = {'default_ind':predict_leader}\n",
    "\n",
    "predict_leader = pd.DataFrame.from_dict(data)\n",
    "\n",
    "LeaderBoardFinal = pd.concat((application_key,predict_leader),axis =1)\n",
    "\n",
    "print(LeaderBoardFinal.shape)\n",
    "\n",
    "LeaderBoardFinal.to_csv('Flubbers_IITRookree_1.csv',index=False,header=False)\n",
    "\n",
    "\n",
    "#Now just by changing the classifier we can compare the f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.023\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.016\n",
      "F1 score for training set: 0.9565217391304348\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.3440559440559441\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.016\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.016\n",
      "F1 score for test set: 0.4370651486401012\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Training set size: {}\".format(len(X_train)))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print( \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print (\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n",
    "\n",
    "train_predict(clf, X_train.sample(n=200, random_state=200), y_train.sample(n=200, random_state=200), X_test, y_test)\n",
    "train_predict(clf, X_train.sample(n=100, random_state=100), y_train.sample(n=100, random_state=100), X_test, y_test)\n",
    "# Note: Keep the test set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 72000\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 2.868\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.031\n",
      "F1 score for training set: 0.9999436587976788\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.4649761486316846\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.016\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.4490285440153514\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.016\n",
      "F1 score for test set: 0.35917114351496543\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "train_predict(dtc, X_train, y_train, X_test, y_test)\n",
    "train_predict(dtc, X_train.sample(n=200, random_state=202), y_train.sample(n=200, random_state=202), X_test, y_test)\n",
    "train_predict(dtc, X_train.sample(n=100, random_state=102), y_train.sample(n=100, random_state=102), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#choosing the best model\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {'max_depth': (1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 'n_estimators': (100, 125, 150, 500)}\n",
    "sss = cross_validation.StratifiedShuffleSplit(y_train, test_size=num_test)\n",
    "gs = GridSearchCV(estimator=clf, n_jobs=-1, scoring=make_scorer(f1_score, pos_label=1), param_grid=parameters,\n",
    "                  cv=sss)\n",
    "gs.fit(X_train, y_train)\n",
    "best_estimator = gs.best_estimator_\n",
    "print(\"best estimator:\\n{}\".format(best_estimator))\n",
    "print ('')\n",
    "print(\"best parameter:\\n{}\".format(gs.best_params_))\n",
    "print('')\n",
    "print(\"F1 score:\\n{}\".format(f1_score(y_test, best_estimator.predict(X_test), pos_label=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
